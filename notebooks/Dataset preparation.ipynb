{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset processing\n",
    "\n",
    "This notebook processes the raw csv outputs from VAERS into Huggingface datasets. It shouldn't generally need to be run by the end user. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35523bbeb2e03eae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import glob\n",
    "import tqdm.notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "from datetime import datetime\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9362802d64424442",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "HF_URL: str = \"chrisvoncsefalvay/vaers-outcomes\"\n",
    "\n",
    "FLAG_COLUMNS: list = [\"DIED\", \"ER_VISIT\", \"HOSPITAL\"]\n",
    "DEMOGRAPHIC_COLUMNS: list = [\"AGE_YRS\", \"SEX\"]\n",
    "ID_COLUMNS: list = [\"VAERS_ID\"]\n",
    "TEXT_COLUMNS: list = [\"SYMPTOM_TEXT\"]\n",
    "\n",
    "TEST_TRAIN_FRACTION: float = 0.3\n",
    "TRAIN_VAL_FRACTION: float = 0.5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34b77edf5a1fce96",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading data files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5f84ddd06e9313e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_aggregate(pattern: str) -> pd.DataFrame:\n",
    "    files = glob.glob(f\"../data/{pattern}\")\n",
    "    dfs = []\n",
    "    for file in tqdm.tqdm(files):\n",
    "        dfs.append(pd.read_csv(file, encoding=\"latin-1\", low_memory=False))\n",
    "\n",
    "    res = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    print(f\"Processed {len(dfs)} files for a total of {len(res)} records.\")\n",
    "        \n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7772ed4b4b51868",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = read_aggregate(\"*VAERSDATA.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "795e389489cbc6cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_keep: list = ID_COLUMNS + DEMOGRAPHIC_COLUMNS + TEXT_COLUMNS + FLAG_COLUMNS + [\"ER_ED_VISIT\"]\n",
    "data = data[_keep]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5297fca83e18b502",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recoding\n",
    "\n",
    "We recode as follows:\n",
    "\n",
    "* For the outcome flags, `NaN` is recoded as `0` and `Y` is recoded as `1`.\n",
    "* `ER_VISIT` and `ER_ED_VISIT` are coalesced into a single column called `ER_VISIT` that is `1`-valued if either is `1`-valued, otherwise it is `0`-valued. This is to manage the renaming of the column in the VAERS data.\n",
    "* `NaN`s in the symptom text will drop the record."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9467a8081810458e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def recode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for column in FLAG_COLUMNS + [\"ER_ED_VISIT\"]:\n",
    "        df[column] = df[column].replace(\"Y\", 1).fillna(0).astype(int)\n",
    "    \n",
    "    df['ER_VISIT'] = df[['ER_VISIT', 'ER_ED_VISIT']].max(axis=1)\n",
    "    \n",
    "    df = df.drop(columns=['ER_ED_VISIT'])\n",
    "    \n",
    "    df = df.dropna(subset=['SYMPTOM_TEXT'])\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aad00c9fe40adb8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = recode(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f23ee0eae1b70387",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c3d8371130ecd5e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Powerset encoding\n",
    "\n",
    "We use powerset encoding to encode the outcomes as a single label, turning a multilabel problem into a multiclass problem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34b09418326e08a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "clf = LabelPowerset()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e64fa1f104c144e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data['label'] = clf.transform(data[FLAG_COLUMNS].values)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0dafd2e8c3c7367",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because `datasets` actually stores labels as integers, we can put them in as human-readable strings and `datasets` will take care of the rest under the hood."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53b26b5a1b58e98b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "\n",
    "for index, row in enumerate(clf.inverse_transform(np.unique(clf.transform(data[FLAG_COLUMNS].values))).toarray()):\n",
    "    # Initialize the list to store the labels for the current row\n",
    "    row_labels = []\n",
    "\n",
    "    # Iterate over each column in the row\n",
    "    for i, value in enumerate(row):\n",
    "        # If the value is 1, add the corresponding label to the list\n",
    "        if value == 1:\n",
    "            row_labels.append(FLAG_COLUMNS[i])\n",
    "            \n",
    "    # If 'DIED' is in the list, remove it and append it at the end â€“ this is purely\n",
    "    # for aesthetic reasons\n",
    "    if 'DIED' in row_labels:\n",
    "        row_labels.remove('DIED')\n",
    "        row_labels.append('DIED')\n",
    "\n",
    "    row_labels = \", \".join(row_labels)\n",
    "\n",
    "    # Add the list of labels for the current row to the dictionary with the row index as the key\n",
    "    labels_dict[index] = row_labels\n",
    "    \n",
    "labels_dict[0] = \"No event\"\n",
    "\n",
    "print(labels_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fb2ed059c21c1d3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data[\"label\"] = data[\"label\"].map(labels_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6587f4e2fb48a9c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test/train/validate split\n",
    "\n",
    "We do a stratified split by age quintile and gender into test, train and validate sets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dae902b111c8ef3c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def stratified_split(df: pd.DataFrame, test_train_fraction: float, train_val_fraction: float, random_state: int = None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    df['AGE_QUINTILE'] = pd.qcut(df['AGE_YRS'], 5, labels = False)\n",
    "    df['STRATIFICATION_VARIABLE'] = df['SEX'].astype(str) + \"_\" + df['AGE_QUINTILE'].astype(str)\n",
    "    df = df.drop(columns=['AGE_QUINTILE'])\n",
    "     \n",
    "    _, train = train_test_split(df, train_size=test_train_fraction, random_state=random_state, stratify=df.STRATIFICATION_VARIABLE)\n",
    "    \n",
    "    val, test = train_test_split(_, train_size=train_val_fraction, random_state=random_state, stratify=_.STRATIFICATION_VARIABLE)\n",
    "    \n",
    "    train = train.drop(columns=\"STRATIFICATION_VARIABLE\")\n",
    "    val = val.drop(columns=\"STRATIFICATION_VARIABLE\")\n",
    "    test = test.drop(columns=\"STRATIFICATION_VARIABLE\") \n",
    "    \n",
    "    return train, test, val"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddee47653c94ff02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train, test, val = stratified_split(data, TEST_TRAIN_FRACTION, TRAIN_VAL_FRACTION)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb16aaad0127ef7d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting to labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d61bfdc4a2879905"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def convert_to_dataset(df: pd.DataFrame) -> datasets.Dataset:\n",
    "    df = df.loc[:, ID_COLUMNS + TEXT_COLUMNS + [\"label\"]]\n",
    "    \n",
    "    # We rename the remaining columns\n",
    "    df = df.rename(columns={\"SYMPTOM_TEXT\": \"text\", \"VAERS_ID\": \"id\"})\n",
    "    \n",
    "    features = datasets.Features({\n",
    "        \"id\": datasets.Value(\"int32\"),\n",
    "        \"text\": datasets.Value(\"string\"),\n",
    "        \"label\": datasets.ClassLabel(\n",
    "            names=list(labels_dict.values())\n",
    "            )})\n",
    "\n",
    "    ds = datasets.Dataset.from_pandas(df, \n",
    "                                      preserve_index=False,\n",
    "                                      features=features)\n",
    "    \n",
    "    return ds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d602444d33b7130",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ds = datasets.DatasetDict()\n",
    "ds[\"train\"] = convert_to_dataset(train)\n",
    "ds[\"test\"] = convert_to_dataset(test)\n",
    "ds[\"val\"] = convert_to_dataset(val)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7c854a072956ca3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ds[\"train\"].features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcf313fdbc1ba08c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ds[\"train\"].features[\"label\"].int2str(ds[\"train\"][5][\"label\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76b47332d4ca3868",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving to Huggingface Hub"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec0167c068238f5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "commit_message = f\"\"\"Data set commit of {len(train) + len(test) + len(val)} records of VAERS data at {datetime.now().isoformat()} from 1990 to 2023, encoded using a powerset multiclass encoding.\"\"\"\n",
    "\n",
    "ds.push_to_hub(HF_URL, \n",
    "               commit_message=commit_message,\n",
    "               create_pr=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "104ffca720a27624",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
